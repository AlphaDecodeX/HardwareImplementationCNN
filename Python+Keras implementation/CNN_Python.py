# -*- coding: utf-8 -*-
"""CNN_Week_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cj1aIC9ZanY-4iQUYoLDqTyzt3Y6PotC
"""

# importing Necessary libraries
from __future__ import absolute_import, division, print_function, unicode_literals
import warnings
from keras import backend as K
import matplotlib.pyplot as plt
from tensorflow.keras import datasets, layers, models
import tensorflow as tf
warnings.filterwarnings("ignore")


# Relu Used For Our CNN Implementation in Verilog, For more info go to Keras Relu with alpha and threshold....documentation

def relu_advanced(x):
    return K.relu(x, max_value=25, alpha=1.0, threshold=2.0)


(train_images, train_labels), (test_images,
 test_labels) = datasets.cifar10.load_data()  # Loading Dataset

# Checking the type of the ImageArray
type(train_images), train_images.ndim, train_images.shape, train_labels.shape


# Converting Images To one channel Gray Scale.....

train_images = tf.image.rgb_to_grayscale(
    train_images,
    name=None
)
test_images = tf.image.rgb_to_grayscale(
    test_images,
    name=None
)

type(train_images)   # Checking the Type of the Images array

train_images = tf.Session().run(train_images)
# Converting Image Array Tensors to Numpy nDim Array
test_images = tf.Session().run(test_images)

# Printing the shape of the train and test images
train_images.shape, test_images.shape

# Image array extraction for Showing in next Cell
train_images_show = train_images[:, :, :, 0]
test_images_show = test_images[:, :, :, 0]

# All Dataset Divison Images Array and labels Array Shape
train_images.shape, test_images.shape, train_images_show.shape, test_images_show.shape

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

plt.figure(figsize=(10, 10))
for i in range(25):
    plt.subplot(5, 5, i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    # Showing the Extracted Images with Labels stored in class_names Array.....
    plt.imshow(train_images_show[i], cmap=plt.cm.binary)
    # The CIFAR labels happen to be arrays,
    # which is why you need the extra index
    plt.xlabel(class_names[train_labels[i][0]])
plt.show()

model = models.Sequential()
# Adding A layer with 5 filters and With Actiation relu_advanced defined by us .... above
model.add(layers.Conv2D(
    5, (3, 3), activation=relu_advanced, input_shape=(32, 32, 1)))
model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Conv2D(1, (3, 3), activation = relu_advanced))                     #  Examples of further addition of convolutional Layers
# model.add(layers.Conv2D(1, (3, 3), activation='relu', input_shape=(32, 32, 1)))
# model.add(layers.MaxPooling2D((2,2)))
# model.add(layers.Conv2D(64, (3, 3),padding = 'same', activation='relu'))
# model.add(layers.MaxPooling2D((2,2)))
# model.add(layers.Conv2D(64, (3, 3), activation='relu'))
# model.add(layers.MaxPooling2D((2,2)))
# model.add(layers.Conv2D(64, (3, 3), activation='relu'))
# model.add(layers.MaxPooling2D((2,2)))
# model.add(layers.Conv2D(128, (3, 3), activation='relu'))
# model.add(layers.MaxPooling2D((2,2)))
# model.add(layers.Conv2D(128, (3, 3), activation='relu'))
# model.add(layers.MaxPooling2D((2,2)))

model.summary()  # Printing Dimensions and Layers of The Added Layers.....

# Producing Fully Connected Neural Network With Activation Function Applied to below Dense Layer(Hidden Layer).....
model.add(layers.Flatten())
# Here also Activation Function is Our Defined Function .....
model.add(layers.Dense(100, activation=relu_advanced))
model.add(layers.Dense(10, activation='softmax'))

model.summary()

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])     # Optimizing the Model Parameters by using 'adam' Optimizer and doing all in iterations...

history = model.fit(train_images, train_labels, epochs=5,  # A full Feed Forward + Back Propagation is collectiiely called as one epoch ..... Here 5 Epochs are taken .. 10 Are recommended.                    validation_data=(test_images, test_labels))

# Accuracy --> It is the Accuracy predicted using Train Dataset while optimizing the network
# Validation Accuracy --> It is the Accuracy predicted using Test Dataset while optimizing the network

# Accuracy --> High And Validation Accuracy --> High means Model is overfitting in Train Data Only. So, Validation Accuracy matters alongwith the Accuracy of the Model.


plt.plot(history.history['acc'], label='acc')
plt.plot(history.history['val_acc'], label='val_acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
# Plotting Accuracy and Validation Accuracy
test_loss, test_acc=model.evaluate(test_images,  test_labels, verbose=2)

# Extracting Model Parameters Shapes using model.get_weights() method.


((model.get_weights())[0]).shape, ((model.get_weights())[1]).shape, ((model.get_weights())[2]).shape, ((
    model.get_weights())[3]).shape, ((model.get_weights())[4]).shape, ((model.get_weights())[5]).shape

# Extracting Filter with Its Biases

filters=model.get_weights()[0]
filters_bias=model.get_weights()[1]

filters.shape  # Filters shape

# Printing Filters applied in Convolution.

for k in range(5):  # No. of Filters .....
    print('Filter'+str(k+1), end="\n--------------------\n")
    for i in range(3):              # All Filters
        for j in range(3):
            print(filters[i][j][0][k])

print("Filter Bias -----------")
filters_bias

# Extracting Weights and Biases of Trained CNN model....

W1=model.get_weights()[2]
B1=model.get_weights()[3]
W2=model.get_weights()[4]
B2=model.get_weights()[5]

# Writing Flattend W1 Parameters into Txt File ......

f=open("W1.txt", 'w')
for i in range(100):
    for j in range(1125):
        f.write(str(W1[j][i]))
        f.write("\n")
        # print(W1[i][j])
f.close()

# Shape of Biases of 1st Layer .....
B1.shape

# Writing Flattend B1 Parameters into Txt File ......

f=open("B1.txt", 'w')
for i in range(100):
    f.write(str(B1[i]))
    f.write("\n")
    # print(B1[i])

f.close()

# Writing Flattend W2 Parameters into Txt File ......

f=open("W2.txt", 'w')
for i in range(10):
    for j in range(100):
        f.write(str(W2[j][i]))
        f.write("\n")
        # print(W1[i][j])
f.close()

# Writing Flattend B2 Parameters into Txt File ......

f=open("B2.txt", 'w')
for i in range(10):
    f.write(str(B2[i]))
    f.write("\n")
    # print(B1[i])

f.close()

# Writing All Trained_Images in a Txt File..... All Flattened For Coe File Conversion For FPGA Implementation ......
f=open('Images.txt', 'w')
for l in range(50000):
    for i in range(32):
        for j in range(32):
            f.write(str(train_images[l][i][j][0]))
            f.write("\n")
f.close()

# Writing All Trained_Images_Labels in a Txt File..... All Flattened For Coe File Conversion For FPGA Implementation ......


f=open("Labels.txt", "w")
for i in range(50000):
    f.write(str(train_labels[i][0]))
    f.write("\n")
f.close()

# Extracting 10 images of Trained_images Dataset with Label as given equals to 9

f=open('Images_9.txt', 'w')
count=0
for l in range(50000):
    if train_labels[l][0] == 9 and count < 10:
        for i in range(32):
            for j in range(32):
                f.write(str(train_images[l][i][j][0]))
                f.write("\n")
        count += 1
f.close()

from tensorflow.keras import backend as K

# create a Keras function to get i-th layer
get_layer_output=K.function(
    inputs=model.layers[0].input, outputs=model.layers[0].output)

# extract output
# Extracting Model 0th Layer output for 13 Image in Trained_Images Dataset  (Print model.layers() and note index
reshape_image=np.expand_dims(train_images[13], axis=0)
                                                        # for print output any of the layer i.e. Layers like max pool, convolution, Flatten, Hidden, Output.....etc.)
layer_output=get_layer_output(reshape_image)

# For First Image Extraction Of Kernal Final Values .....
output_filters=layer_output
# print(get_layer_output)

output_filters.shape

# Finding Accuracy
f=open("Labels.txt", 'w')
g=open("Incorrect_Labels.txt", 'w')
from tensorflow.keras import backend as K
# create a Keras function to get i-th layer
get_layer_output=K.function(
    inputs=model.layers[0].input, outputs=model.layers[3].output)
correct_images=[]
# extract output
count=0
num=50000
for i in (range(num)):
    reshape_image=np.expand_dims(train_images[i], axis=0)
    layer_output=get_layer_output(reshape_image)
    if np.argmax(layer_output) == train_labels[i]:
        correct_images.append(i)
        f.write(str(train_labels[i][0]))
        f.write("\n")
        count += 1
    if np.argmax(layer_output) != train_labels[i]:
        # correct_images.append(i)
        g.write(str(train_labels[i][0]))
        g.write("\n")
accuracy=(count/num)*100
f.close()
g.close()



# Extracting Intermediate Outputs Of Layers .....
from tensorflow.keras import backend as K
get_layer_output=K.function(
    inputs=model.layers[0].input, outputs=model.layers[2].output)

reshape_image=np.expand_dims(train_images[0], axis=0)
layer_output=get_layer_output(reshape_image)

# Extracting Max Pooled or Flatten Output for 0th Image from train_images dataset
f=open("Flatten.txt", "w")
for i in range(1125):
    f.write(str(layer_output[:, i][0]))
    f.write(" ")
    if((i+1) % 15 == 0):
        f.write("\n")
    if((i+1) % 225 == 0):
        f.write("------------------------------------------------------------------------------------------------------")
        f.write("\n")
f.close()

model.layers
